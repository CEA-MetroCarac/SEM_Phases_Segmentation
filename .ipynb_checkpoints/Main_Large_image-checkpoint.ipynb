{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560aca72-96e9-4b42-b481-eb2964836399",
   "metadata": {},
   "source": [
    "# Load the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee459cbf-7a12-41a2-bfa0-a37dd09da936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "import skimage.io as ski\n",
    "import os\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image\n",
    "# from patchify import patchify\n",
    "import tifffile as tiff\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from Training_lib import Load_training_data, Split_data, Load_and_prepare_data, Main_model\n",
    "from Prediction_lib import Large_pred, updated_Large_pred\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import normalize, to_categorical\n",
    "import timeit\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import timeit\n",
    "from Patches_lib import generate_patches\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f27bda-1538-4571-991b-5241e74ed8b4",
   "metadata": {},
   "source": [
    "# Use GPU\n",
    "\n",
    "### Memory Usage Limitation During Training\n",
    "\n",
    "To ensure fair usage of shared resources on the cluster, it's important to **limit the amount of memory (in GB) used during training**.\n",
    "\n",
    "Doing so prevents the training process from occupying all available memory, which could negatively impact other users working on the same cluster.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Consider setting memory constraints explicitly in your code or job configuration to avoid monopolizing system resources.<b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37873c-bc50-443d-8068-8a45e814571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "Gb_of_RAM = 10\n",
    "\n",
    "tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024*Gb_of_RAM)])\n",
    "\n",
    "\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(\"Using\", Gb_of_RAM, \"Gb of RAM from \", len(gpus) ,\"Physical GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922ba6c-e34b-4583-a9bf-7432dceeab3f",
   "metadata": {},
   "source": [
    "# Load model and Preform segmentation on Large Images\n",
    "\n",
    "## Direct prediction\n",
    "\n",
    "Prediction is performed directly using the trained U-Net model. The large image is then reconstructed using a sliding window approach to smooth patch borders and reduce misclassifications caused by edge effects.\n",
    "\n",
    "- `Patch_size`  \n",
    "  This defines the size (in pixels) of square patches that the input images are divided into.  \n",
    "  For example, if `Patch_size` is $256$, each image will be processed in blocks of $256 \\times 256$ pixels.  \n",
    "  This is commonly used in patch-based training for deep learning models, particularly in image segmentation tasks.\n",
    "\n",
    "- `n_classes`  \n",
    "  This indicates the total number of classes to be predicted in the image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc8bdf-fdd7-4816-893d-dbe2e82f9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patch_size = 256\n",
    "Data_folder = 'Data'\n",
    "n_classes = 4\n",
    "Training_param = False\n",
    "\n",
    "# Model name and emplacement:\n",
    "Save_name      = 'UNet_' + str(Patch_size) + 'px_v1'\n",
    "model_folder   = 'Saved_models/'\n",
    "history_folder = 'Saved_history/'\n",
    "\n",
    "if not os.path.exists(model_folder) and not os.path.exists(history_folder):\n",
    "    os.mkdir(model_folder)\n",
    "    os.mkdir(history_folder)\n",
    "    print(\"Model and history directories created\")\n",
    "else:\n",
    "    print(\"The model and history directories already exist.\")\n",
    "\n",
    "# Training/Loading:\n",
    "start = timeit.default_timer()\n",
    "\n",
    "model, history = Main_model(Save_name=Save_name, model_folder=model_folder, history_folder=history_folder, \n",
    "                            n_classes= n_classes, Patch_size = Patch_size,\n",
    "                            Training_param = Training_param)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "total_time = stop - start\n",
    "\n",
    "if Training_param:\n",
    "    print(f\"Total training time is = {np.floor(total_time/60):.0f}:%02d\" % (total_time - np.floor(total_time / 60) * 60), \"min\")\n",
    "else: \n",
    "    print(f\"Total loading time is = {np.floor(total_time/60):.0f}:%02d\" % (total_time - np.floor(total_time / 60) * 60), \"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acace2b6-d53e-408b-bfbc-46da3dbc09e5",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "One important parameter in this part of the code is <b>`s`</b>, which represents the <b>stride</b> of the sliding window.\n",
    "</div>\n",
    "\n",
    "\n",
    "- `s` is a **positive integer**.\n",
    "- It defines the number of pixels the window moves at each step.\n",
    "- It effectively controls how the image is **padded** and how the sliding window **covers** the full image.\n",
    "\n",
    "Choosing an appropriate stride is crucial to ensure full image coverage and to manage overlaps or gaps between patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7b317-db1e-444c-ab5b-6be622e01787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "All_Images_names = sorted(list(Path(Data_folder+'/SEM Image/').glob('*.tif')))\n",
    "All_Labels_names = sorted(list(Path(Data_folder+'/Labels/').glob('*.tif')))\n",
    "\n",
    "def calculate_accuracy(gt, pred):\n",
    "    \"\"\"Calculate the pixel accuracy between ground truth and prediction.\"\"\"\n",
    "    correct = np.sum(gt == pred)\n",
    "    total = gt.size\n",
    "    return correct / total\n",
    "\n",
    "vec = [256,32]\n",
    "for II in range(7):\n",
    "    for s in vec:\n",
    "        Image_name = All_Images_names[II]\n",
    "        Label_name = All_Labels_names[II]\n",
    "        \n",
    "        Probability_map, Final_prediction = updated_Large_pred(Image_name, Label_name, model, Patch_size, stride=s, Norm=True, tech=None)\n",
    "\n",
    "        target = ski.imread(Label_name)\n",
    "        target = target[0:Final_prediction.shape[0], 0:Final_prediction.shape[1]]/85\n",
    "        accuracy = calculate_accuracy(target, Final_prediction)\n",
    "        accuracy_percent = accuracy*100  # Convert to percentage\n",
    "        print(accuracy_percent)\n",
    "        \n",
    "        # Save results\n",
    "        Res_folder = Data_folder+'/Model_prediction/'\n",
    "        if not os.path.exists(Res_folder):\n",
    "            os.mkdir(Res_folder)\n",
    "            print(\"Results directory created\")\n",
    "        else:\n",
    "            print(\"Results directory already exist.\")\n",
    "        \n",
    "        tiff.imwrite(Res_folder+f'Image_{II}_prediction_{s}.tif', Final_prediction.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54994a0f-ddf8-43b2-9c7f-25c167d7c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final prediction (binary or categorical mask)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(Final_prediction, cmap='gray')\n",
    "plt.title(\"Final Prediction\", fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display max probability map with colorbar\n",
    "plt.figure(figsize=(15, 15))\n",
    "prob_map = np.max(Probability_map, axis=-1)\n",
    "cmap = plt.cm.RdYlGn\n",
    "red_yellow_green_cmap = LinearSegmentedColormap.from_list(\"RedYellowGreen\", [\"red\", \"yellow\", \"green\"])\n",
    "im = plt.imshow(prob_map, cmap=red_yellow_green_cmap)\n",
    "plt.title(\"Maximum Probability Map\", fontsize=16)\n",
    "plt.colorbar(im)#, fraction=0.046, pad=0.04)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae4801-99c3-42a0-9a8a-deb82da281a6",
   "metadata": {},
   "source": [
    "## Ensemble prediction\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>For info:</b> This technique can be more time-consuming, as multiple models are loaded at each iteration of the sliding window. However, it can yield better generalization and improved prediction results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3d1dd-e14b-4c94-8132-f10fcc093320",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patch_size = 256\n",
    "Data_folder = 'Data'\n",
    "n_classes = 4\n",
    "Training_param = False\n",
    "\n",
    "All_Images_names = sorted(list(Path(Data_folder+'/SEM Image/').glob('*.tif')))\n",
    "All_Labels_names = sorted(list(Path(Data_folder+'/Labels/').glob('*.tif')))\n",
    "\n",
    "II = 2\n",
    "s = 128\n",
    "\n",
    "Image_name = All_Images_names[II]\n",
    "Label_name = All_Labels_names[II]\n",
    "\n",
    "Probability_map_ens, Final_prediction_ens = Large_pred(Image_name, Label_name, Patch_size=Patch_size, stride=s, Norm=True, tech='Ensemble')\n",
    "\n",
    "# Save results\n",
    "Res_folder = Data_folder+'/Model_prediction/'\n",
    "if not os.path.exists(Res_folder):\n",
    "    os.mkdir(Res_folder)\n",
    "    print(\"Results directory created\")\n",
    "else:\n",
    "    print(\"Results directory already exist.\")\n",
    "\n",
    "tiff.imwrite(Res_folder+f'Image_{II}_prediction_{s}.tif', Final_prediction.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc2315-5db2-435b-8c87-c7c335f152ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final prediction (binary or categorical mask)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(Final_prediction_ens, cmap='gray')\n",
    "plt.title(\"Final Prediction\", fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display max probability map with colorbar\n",
    "plt.figure(figsize=(15, 15))\n",
    "prob_map = np.max(Probability_map_ens, axis=-1)\n",
    "cmap = plt.cm.RdYlGn\n",
    "red_yellow_green_cmap = LinearSegmentedColormap.from_list(\"RedYellowGreen\", [\"red\", \"yellow\", \"green\"])\n",
    "im = plt.imshow(prob_map, cmap=red_yellow_green_cmap)\n",
    "plt.title(\"Maximum Probability Map\", fontsize=16)\n",
    "plt.colorbar(im)#, fraction=0.046, pad=0.04)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
